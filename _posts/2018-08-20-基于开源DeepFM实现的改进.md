---
layout:     post
title:      对DeepFM实现的稀疏及Multi-hot改进
subtitle:   改进
date:       2018-08-20
author:     Zach
header-img: img/post-bg-kuaidi.jpg
catalog: true
tags:
    - DeepFM
    - 改进
    - 变长特征
    - Multi-hot特征
---

## 概要
&emsp;&emsp;DeepFM单机版模型基于[ChenglongChen的实现](https://github.com/ChenglongChen/tensorflow-DeepFM) ，不过该版本的实现中，FM层不支持稀疏输入，且本次使用的样本特征中存在长度可变的list型特征（又称 多值离散特征、Multi-hot)。


## DeepFM介绍
<div align=center>![DeepFM 图](https://raw.githubusercontent.com/Zachary4biz/Tahiti_any_data/master/pics/DeepFM.png "Optional title"){:height="70%" width="70%"}</div>

- ### 调参的时候有个比较核心的观念：
    + Deep侧注重的是"generalization"，增加网络层数、神经元个数并不会出现很严重的过拟合
    + FM侧注重的是"memorization"，包括增大embedding_size 参数的时候也是在考虑对"memorization"的提升。

- ### 背景
    + CTR任务的特征：高维且稀疏
    + 传统模型
        * 需要人工特征组合，要求深入的业务理解且难有三阶以上的特征组合
        * LR、GBDT+LR、FM/FFM
    + DNN模型
        * 通过embedding方式将特征维数控制在定长、低维有利于DNN模型输入
        * 产生高阶特征组合，但是不注重一阶二阶的特征
        * PNN、FNN
    + DeepFM
        * 通过embedding方式将特征维数控制在定长、低维有利于DNN模型输入
        * FM产生低阶特征，Deep产生高阶特征
        * 类似的还有WDL(Wide&Deep)，不过WDL仍需要在Wide部分人工特征组合

&emsp;&emsp;CTR任务的特点是有 "大量、高维、稀疏的离散特征"，传统的CTR模型大概有 LR、GBDT+LR、FM/FFM，目的就是对大量特征进行人工或者自动的特征组合。发展到后来，涉及深度学习的模型又分为"串行结构"和"并行结构"两种，这里的”串行并行“指的是将DNN与传统LR模型或FM模型结合的方式是串行还是并行，DeepFM属于并行结构，是FM与DNN的结合。之所以将DNN和FM结合，目的是将DNN学习到的高阶特征与FM产生的一阶、二阶特征融合，FM捕获了二阶的特征组合并且提供了embedding形式将高维稀疏向量映射到低维稠密向量，DNN利用各个特征的embedding向量作为输入可以避免模型输入过大(本例直接用one-hot有11万维)，并且捕获四阶、五阶的高阶特征组合。[部分深度学习模型的结构示例](#DNN_models)

- ### 思路
    + 特征embedding进行随机初始化，FM和Deep共享embedding之后的结果，FM进行一阶和二阶的特征组合，Deep进行更高阶的特征组合，Deep各个隐层的全连接权重、FM一阶和二阶的权重、embedding向量这三块都会在训练中进行更新。最后会将FM和Deep层的输出再做一个全连接，然后sigmoid输出。
    + 针对embedding这块可以想象是在"用神经网络做embedding"，效果应当更好

- ### Embedding介绍<br/>
&emsp;&emsp;类似于做向量基变换，将高维稀疏的one-hot特征映射成低维稠密的特征。每个特征的embedding向量通常随机初始化为0~0.01之间的值，在训练过程中更新。
    + 以向量为例子：<br/>
        * 在基向量```i=(1,0,0)``` ```j=(0,1,0)``` ```k=(0,0,1)```空间中，```a=1*i+1*j+2*k``` 则向量```a```表示为```(1,1,2)```
        * 如果使用基向量```m=(1,1,0)``` ```n=(0,0,2)```则有```a=1*m+1*n```，在基向量```m```和```n```中向量```a```的表示为```(1,1)```
    + 具体特征例子：<br/>
    ![流程图](https://raw.githubusercontent.com/Zachary4biz/Tahiti_any_data/master/pics/example_of_embedding.png "Optional title")
- ### 多值离散特征的处理<br/>
 &emsp;&emsp;参考YouTube的方式，对该变长特征的每种取值进行embedding后再按每个用户取到的值对应的embeddings求均值，大致思路如下：
    + 假设该特征 ```Feature_1``` 有1w种取值，且每个样本可以取多个值，如用户观看历史这样一个list，不同样本的“观看历史”特征长度不一样。
    + 随机初始化1w个8维的向量作为隐向量参数，用户A的```Feature_1```取值为 idx:```[17 199 388]```，则取到对应的隐向量参数，求隐向量各个维度的均值作为最终输出<br/>
    ![youtube_example](https://ws1.sinaimg.cn/large/d3434ac6ly1fuplsmjqy8j20xi0owds0.jpg "Optional title"){:height="90%" width="90%"}
    + 流程示例如下<br/>
    ![multi_hot_embedding](https://raw.githubusercontent.com/Zachary4biz/Tahiti_any_data/master/pics/multi_hot_embedding_flow.png "Optional title")
    + 这里对于多值离散特征还可以参考阿里DIN模型的处理方式，引入Attention机制
- ### FM
    + 前半部分对FM的阐述易于理解
        * 原文：https://www.analyticsvidhya.com/blog/2018/01/factorization-machines/
        * 译文：http://www.360doc.com/content/18/0118/13/47852988_723049882.shtml
    
- ### Deep    
    + [直接基于ChenglongChen开源实现的DeepFM梳理](https://ask.hellobi.com/blog/wenwen/11840)

## 待验证的想法
- 这里的实现其实是把连续特征当成了多个离散特征在用，考虑把连续特征单独作为输入放到NN里面

## 结论
- 相比于LR 0.67 提升到 0.70
- 华为自己的实验结果：</br>
![](https://ws1.sinaimg.cn/large/d3434ac6ly1fuzy28lp9tj20dy07k76c.jpg)


## 报错及解决
- 报错: timeline工具 ```Couldn't open CUDA library libcupti.so.8.0. LD_LIBRARY_PATH: ```
    + 这基本是所有初次使用timeline工具必定会碰上的问题
    + 尝试一： ```sudo apt-get install libcupti-dev```（Ubuntu才有apt-get, 使用```cat /etc/*release*```查看当前linux发行版)
    + 尝试二：CentOS使用yum ```sudo yum install libcupti-dev```（yum官方源没有libcupti-dev，但是发现对于CentOS来说，在安装cuda的时候就已经把cupti安装好了，查看目录```/usr/local/cuda-8.0/extras/CUPTI/```)
    + 解决方案：添加LD_LIBRARY_PATH环境变量```export LD_LIBRARY_PATH=/usr/local/cudnn/cuda/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH```

## 参考
- [Youtube论文](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)
- [知乎专栏](https://zhuanlan.zhihu.com/p/25343518)
- [legendavid的博客 主流CTR预估模型的演化及对比](https://blog.csdn.net/LegenDavid/article/details/80064135)

## 附
- #### <span id="DNN_models">部分深度学习模型的结构示例</span>
    + ##### 并行结构：<br/>
    ![并行结构](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph33qmqdj20y40gpahl.jpg "Optional title"){:height="70%" width="70%"}
        + ![DeepFM](https://ws1.sinaimg.cn/large/d3434ac6ly1fupgu0nekdj20zm0hj7d9.jpg){:height="50%" width="50%"}
        + ![Deep&Cross](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph1gwnusj20za0ghqbl.jpg "Optional title"){:height="50%" width="50%"}
        + ![Wide&Deep](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph223j8sj20zn0h87cv.jpg "Optional title"){:height="50%" width="50%"}
    + ##### 串行结构:<br/>
    ![串行结构](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph45ne7sj20sa0gzq92.jpg "Optional title"){:height="70%" width="70%"}
        + ![PNN](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph4pb827j20yr0glwl8.jpg "Optional title"){:height="50%" width="50%"}
        + ![NFM](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph53wm3zj20yy0g1n37.jpg "Optional title"){:height="50%" width="50%"}
        + ![AFM](https://ws1.sinaimg.cn/large/d3434ac6ly1fuph5edf3kj218k0mbqd1.jpg "Optional title"){:height="50%" width="50%"}





